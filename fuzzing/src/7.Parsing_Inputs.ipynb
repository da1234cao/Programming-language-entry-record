{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 解析输入"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "使用文法可以生成相应语言的字符串。反过来，给定字符串，可以将该字符串分解为语法树的组成部分(这些组成部分对应于用于生成该字符串的派生树的语法部分)。\n",
    "本章，会通过语法分析，将有效的种子输入，分解&解析成对应的语法树组成部分。这允许我们变异、交叉和重新组合它们的部分，以便生成新的有效的、稍加更改的输入(即fuzz)。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入内容\n",
    "from fuzzingbook.fuzzingbook_utils.Grammars import EXPR_GRAMMAR, START_SYMBOL, RE_NONTERMINAL, is_valid_grammar\n",
    "from fuzzingbook.fuzzingbook_utils.GrammarFuzzer import GrammarFuzzer, display_tree, tree_to_string, dot_escape\n",
    "import string"
   ]
  },
  {
   "source": [
    "## 被测试程序"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_inventory(inventory):\n",
    "    res = []\n",
    "    for vehicle in inventory.split('\\n'):\n",
    "        ret = process_vehicle(vehicle)\n",
    "        res.extend(ret)\n",
    "    return '\\n'.join(res)\n",
    "\n",
    "def process_vehicle(vehicle):\n",
    "    year, kind, company, model, *_ = vehicle.split(',')\n",
    "    if kind == 'van':\n",
    "        return process_van(year, company, model)\n",
    "\n",
    "    elif kind == 'car':\n",
    "        return process_car(year, company, model)\n",
    "\n",
    "    else:\n",
    "        raise Exception('Invalid entry')\n",
    "\n",
    "def process_van(year, company, model):\n",
    "    res = [\"We have a %s %s van from %s vintage.\" % (company, model, year)]\n",
    "    iyear = int(year)\n",
    "    if iyear > 2010:\n",
    "        res.append(\"It is a recent model!\")\n",
    "    else:\n",
    "        res.append(\"It is an old but reliable model!\")\n",
    "    return res\n",
    "\n",
    "def process_car(year, company, model):\n",
    "    res = [\"We have a %s %s car from %s vintage.\" % (company, model, year)]\n",
    "    iyear = int(year)\n",
    "    if iyear > 2016:\n",
    "        res.append(\"It is a recent model!\")\n",
    "    else:\n",
    "        res.append(\"It is an old but reliable model!\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们需要测试process_inventory函数\n",
    "\n",
    "mystring = \"\"\"\\\n",
    "1997,van,Ford,E350\n",
    "2000,car,Mercury,Cougar\\\n",
    "\"\"\"\n",
    "print(process_inventory(mystring))"
   ]
  },
  {
   "source": [
    "## 测试程序而创建的文法"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "下面的文法定义的很宽泛。有效的测试输入，是这个文法生成语言的子集。\n",
    "\n",
    "宽泛，导致很难生成正确的输入，导致测试相当低效。\n",
    "\n",
    "方案一：我们可以修改下文法，在文法中，将\"van\",\"car\"作为其中可能的终结符。\n",
    "\n",
    "方案二：修改GrammarFuzzer中扩展节点的函数，加入一个存储\"van\",\"car\"的扩展可能，使得有一定几率使用这些特定的值。\n",
    "\n",
    "方案三： In fact, it would be nice if we could extract the template and valid values from samples, and use them in our fuzzing. How do we do that? The quick answer to this question is: Use a parser.\n",
    "【事实上，如果我们能从样本中提取模板和有效值，并在我们的模糊中使用它们，那就太好了。我们怎么做呢?对这个问题的快速回答是:使用解析器。】\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_GRAMMAR = {\n",
    "    '<start>': ['<csvline>'],\n",
    "    '<csvline>': ['<items>'],\n",
    "    '<items>': ['<item>,<items>', '<item>'],\n",
    "    '<item>': ['<letters>'],\n",
    "    '<letters>': ['<letter><letters>', '<letter>'],\n",
    "    '<letter>': list(string.ascii_letters + string.digits + string.punctuation + ' \\t\\n')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = GrammarFuzzer(CSV_GRAMMAR, min_nonterminals=4,log=False)\n",
    "gf.fuzz()"
   ]
  },
  {
   "source": [
    "## 一个特定的解析器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以为某一行内部元素可能包含字符串，比如下面这个\n",
    "# mystring = '''\\\n",
    "# 1997,Ford,E350,\"ac, abs, moon\",3000.00\\\n",
    "# '''\n",
    "# 所以以逗号作为分割。如果从左到由分割的时候，遇见了引号，引号内部为一整体。非引号内部任然使用逗号分割。\n",
    "# 其中的整体是这种结构： \"*\",但是引号里面不要加引号了，处理不了，比如下面这个\n",
    "# mystring = '''\\\n",
    "# 1999,Chevy,\"Venture \\\\\"Extended Edition, Very Large\\\\\"\",,5000.00\\\n",
    "# '''\n",
    "# 丫的，我没想出来这个”解决办法“，看书中的代码才明白\n",
    "\n",
    "def parse_quote(string, i):\n",
    "    v = string[i + 1:].find('\"')\n",
    "    return v + i + 1 if v >= 0 else -1\n",
    "\n",
    "def find_comma(string, i):\n",
    "    slen = len(string)\n",
    "    while i < slen:\n",
    "        if string[i] == '\"':\n",
    "            i = parse_quote(string, i)\n",
    "            if i == -1:\n",
    "                return -1\n",
    "        if string[i] == ',':\n",
    "            return i\n",
    "        i += 1\n",
    "    return -1\n",
    "\n",
    "def comma_split(string):\n",
    "    slen = len(string)\n",
    "    i = 0\n",
    "    while i < slen:\n",
    "        c = find_comma(string, i)\n",
    "        if c == -1:\n",
    "            yield string[i:]\n",
    "            return\n",
    "        else:\n",
    "            yield string[i:c]\n",
    "        i = c + 1\n",
    "\n",
    "def parse_csv(mystring):\n",
    "    children = []\n",
    "    tree = (START_SYMBOL, children)\n",
    "    for i, line in enumerate(mystring.split('\\n')):\n",
    "        children.append((\"record %d\" % i, [(cell, [])\n",
    "                                           for cell in comma_split(line)]))\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_graph(dot):\n",
    "    dot.attr('node', shape='plain')\n",
    "    dot.graph_attr['rankdir'] = 'LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_node(predicate):\n",
    "    # 这个函数很漂亮。node_atrr的函数，需要四个参数。\n",
    "    def hl_node(dot, nid, symbol, ann):\n",
    "        if predicate(dot, nid, symbol, ann):\n",
    "            dot.node(repr(nid), dot_escape(symbol), fontcolor='red')\n",
    "        else:\n",
    "            dot.node(repr(nid), dot_escape(symbol))\n",
    "    return hl_node\n",
    "\n",
    "# 这里人为认为是错误节点的序号；错误的节点，高亮显示\n",
    "bad_nodes = {5, 6, 7} \n",
    "def hl_predicate(_d, nid, _s, _a): return nid in bad_nodes\n",
    "highlight_err_node = highlight_node(hl_predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fbc73f407f0>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"324pt\" height=\"174pt\"\n viewBox=\"0.00 0.00 324.00 174.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 170)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-170 320,-170 320,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<text text-anchor=\"middle\" x=\"20\" y=\"-71.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;start&gt;</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<text text-anchor=\"middle\" x=\"99\" y=\"-71.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">record 0</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M40.3445,-75.5C48.0799,-75.5 57.1086,-75.5 65.731,-75.5\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.9326,-79.0001 75.9326,-75.5 65.9325,-72.0001 65.9326,-79.0001\"/>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<text text-anchor=\"middle\" x=\"237\" y=\"-154.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1999</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M103.3886,-83.1754C111.9321,-97.3637 132.2393,-127.6024 158,-142.5 174.6339,-152.1195 196.1521,-156.0229 212.5293,-157.5746\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"212.6995,-161.0954 222.9228,-158.3144 213.1966,-154.1131 212.6995,-161.0954\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<text text-anchor=\"middle\" x=\"237\" y=\"-121.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Chevy</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M109.7761,-83.1475C121.2168,-90.9128 140.0847,-102.7298 158,-109.5 174.3792,-115.6897 193.6198,-119.651 209.0118,-122.0836\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.5708,-125.5562 218.9705,-123.5321 209.5784,-118.6291 208.5708,-125.5562\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<text text-anchor=\"middle\" x=\"237\" y=\"-88.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&quot;Venture \\&quot;Extended Edition</text>\n</g>\n<!-- 1&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>1&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M122.0981,-78.3454C134.2458,-79.8419 149.8675,-81.7663 165.6531,-83.7109\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"165.6624,-87.2384 176.0153,-84.9874 166.5183,-80.2909 165.6624,-87.2384\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<text text-anchor=\"middle\" x=\"237\" y=\"-55.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#ff0000\"> Very Large\\&quot;&quot;</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M122.0981,-72.822C139.4526,-70.8098 163.8972,-67.9757 185.781,-65.4384\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.4169,-68.8882 195.9472,-64.2597 185.6106,-61.9348 186.4169,-68.8882\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n</g>\n<!-- 1&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>1&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.1808,-67.7852C110.2256,-67.7559 110.2705,-67.7266 110.3155,-67.6972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.9929,-76.0111 110.4508,-67.6088 100.1626,-70.15 103.9929,-76.0111\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<text text-anchor=\"middle\" x=\"237\" y=\"-3.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#ff0000\">5000.00</text>\n</g>\n<!-- 1&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>1&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M105.4112,-67.9348C115.4294,-56.6319 135.9457,-35.4922 158,-24.5 172.2463,-17.3995 189.3826,-13.2536 204.0488,-10.8381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.8189,-14.2632 214.2148,-9.3676 203.8167,-7.3353 204.8189,-14.2632\"/>\n</g>\n</g>\n</svg>\n"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "mystring = '''\\\n",
    "1997,Ford,E350,\"ac, abs, moon\",3000.00\\\n",
    "'''\n",
    "tree = parse_csv(mystring)\n",
    "display_tree(tree, log=False, node_attr=highlight_err_node,\n",
    "             graph_attr=lr_graph)"
   ]
  },
  {
   "source": [
    "# 暂时跳过本章；暂时不关系内部如何实现，从字符串倒推语法树的实现。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}