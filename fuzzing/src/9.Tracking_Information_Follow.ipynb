{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 追踪信息流\n",
    "\n",
    "如果只是不正确，却没有触发crash该怎么办？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pdb\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在内存中构建一个不靠谱的数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVENTORY = \"\"\"\\\n",
    "1997,van,Ford,E350\n",
    "2000,car,Mercury,Cougar\n",
    "1999,car,Chevy,Venture\\\n",
    "\"\"\"\n",
    "\n",
    "VEHICLES = INVENTORY.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DB:\n",
    "    ###### 数据库初始化 #######\n",
    "    def __init__(self, db={}):\n",
    "        # 初始化数据库\n",
    "        self.db = dict(db)\n",
    "\n",
    "\n",
    "    ####### 表结构 ##########\n",
    "    def create_table(self, table, defs):\n",
    "        # 创建表\n",
    "        self.db[table] = (defs, [])\n",
    "\n",
    "    def table(self, t_name):\n",
    "        # 检索表，返回表结构\n",
    "        if t_name in self.db:\n",
    "            return self.db[t_name]\n",
    "        raise SQLException('Table (%s) was not found' % repr(t_name))\n",
    "\n",
    "    def column(self, table_decl, c_name):\n",
    "        # 返回table_decl表，c_name列的定义\n",
    "        if c_name in table_decl: \n",
    "            return table_decl[c_name]\n",
    "        raise SQLException('Column (%s) was not found' % repr(c_name))\n",
    "\n",
    "    \n",
    "    ######## 表的增删改查 ##########\n",
    "    def sql(self, query):\n",
    "        methods = [('select ', self.do_select), \n",
    "                   ('update ', self.do_update),\n",
    "                   ('insert into ', self.do_insert),\n",
    "                   ('delete from', self.do_delete)]\n",
    "        for key, method in methods:\n",
    "            if query.startswith(key):\n",
    "                return method(query[len(key):])\n",
    "        raise SQLException('Unknown SQL (%s)' % query)\n",
    "\n",
    "\n",
    "    def do_select(self, query):\n",
    "        FROM, WHERE = ' from ', ' where '\n",
    "        table_start = query.find(FROM)\n",
    "        if table_start < 0:\n",
    "            raise SQLException('no table specified')\n",
    "\n",
    "        where_start = query.find(WHERE)\n",
    "        select = query[:table_start]\n",
    "\n",
    "        if where_start >= 0:\n",
    "            t_name = query[table_start + len(FROM):where_start]\n",
    "            where = query[where_start + len(WHERE):]\n",
    "        else:\n",
    "            t_name = query[table_start + len(FROM):]\n",
    "            where = ''\n",
    "        _, table = self.table(t_name) # 前面的defs用不着\n",
    "\n",
    "        if where:\n",
    "            selected = self.expression_clause(table, \"(%s)\" % where)\n",
    "            selected_rows = [hm for i, data, hm in selected if data]\n",
    "        else:\n",
    "            selected_rows = table\n",
    "\n",
    "        rows = self.expression_clause(selected_rows, \"(%s)\" % select)\n",
    "        return [data for i, data, hm in rows]\n",
    "    \n",
    "    def expression_clause(self, table, statement):\n",
    "        selected = []\n",
    "        for i, hm in enumerate(table):\n",
    "            selected.append((i, self.my_eval(statement, {}, hm), hm))\n",
    "\n",
    "        return selected\n",
    "        \n",
    "    def my_eval(self, statement, g, l):\n",
    "        try:\n",
    "            return eval(statement, g, l)\n",
    "        except:\n",
    "            raise SQLException('Invalid WHERE (%s)' % repr(statement))\n",
    "    \n",
    "\n",
    "    def do_insert(self, query):\n",
    "        VALUES = ' values '\n",
    "        table_end = query.find('(')\n",
    "        t_name = query[:table_end].strip()\n",
    "        names_end = query.find(')')\n",
    "        decls, table = self.table(t_name)\n",
    "        names = [i.strip() for i in query[table_end + 1:names_end].split(',')]\n",
    "\n",
    "        # verify columns exist\n",
    "        for k in names:\n",
    "            self.column(decls, k)\n",
    "\n",
    "        values_start = query.find(VALUES)\n",
    "\n",
    "        if values_start < 0:\n",
    "            raise SQLException('Invalid INSERT (%s)' % repr(query))\n",
    "\n",
    "        values = [\n",
    "            i.strip() for i in query[values_start + len(VALUES) + 1:-1].split(',')\n",
    "        ]\n",
    "\n",
    "        if len(names) != len(values):\n",
    "            raise SQLException(\n",
    "                'names(%s) != values(%s)' % (repr(names), repr(values)))\n",
    "\n",
    "        # dict lookups happen in C code, so we cant use that\n",
    "        # 数据库中的每一项用键值对的方式存储，非常臃肿，但便于select查找。\n",
    "        kvs = {}\n",
    "        for k,v in zip(names, values):\n",
    "            for key,kval in decls.items():\n",
    "                if k == key:\n",
    "                    kvs[key] = self.convert(kval, v)\n",
    "        table.append(kvs)\n",
    "\n",
    "    def convert(self, cast, value):\n",
    "        try:\n",
    "            return cast(ast.literal_eval(value))\n",
    "        except:\n",
    "            raise SQLException('Invalid Conversion %s(%s)' % (cast, value))\n",
    "    \n",
    "\n",
    "    def do_update(self, query):\n",
    "        SET, WHERE = ' set ', ' where '\n",
    "        table_end = query.find(SET)\n",
    "\n",
    "        if table_end < 0:\n",
    "            raise SQLException('Invalid UPDATE (%s)' % repr(query))\n",
    "\n",
    "        set_end = table_end + 5\n",
    "        t_name = query[:table_end]\n",
    "        decls, table = self.table(t_name)\n",
    "        names_end = query.find(WHERE)\n",
    "\n",
    "        if names_end >= 0:\n",
    "            names = query[set_end:names_end]\n",
    "            where = query[names_end + len(WHERE):]\n",
    "        else:\n",
    "            names = query[set_end:]\n",
    "            where = ''\n",
    "\n",
    "        sets = [[i.strip() for i in name.split('=')]\n",
    "                for name in names.split(',')]\n",
    "\n",
    "        # verify columns exist\n",
    "        for k, v in sets:\n",
    "            self.column(decls, k)\n",
    "\n",
    "        if where:\n",
    "            selected = self.expression_clause(table, \"(%s)\" % where)\n",
    "            updated = [hm for i, d, hm in selected if d]\n",
    "        else:\n",
    "            updated = table\n",
    "\n",
    "        for hm in updated:\n",
    "            for k, v in sets:\n",
    "                # we can not do dict lookups because it is implemetned in C.\n",
    "                for key, kval in decls.items():\n",
    "                    if key == k:\n",
    "                        hm[key] = self.convert(kval, v)\n",
    "\n",
    "        return \"%d records were updated\" % len(updated)\n",
    "\n",
    "\n",
    "    def do_delete(self, query):\n",
    "        WHERE = ' where '\n",
    "        table_end = query.find(WHERE)\n",
    "        if table_end < 0:\n",
    "            raise SQLException('Invalid DELETE (%s)' % query)\n",
    "        t_name = query[:table_end].strip()\n",
    "        _, table = self.table(t_name)\n",
    "        where = query[table_end + len(WHERE):]\n",
    "        selected = self.expression_clause(table, \"%s\" % where)\n",
    "        deleted = [i for i, d, hm in selected if d]\n",
    "        for i in sorted(deleted, reverse=True):\n",
    "            del table[i]\n",
    "        return \"%d records were deleted\" % len(deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 测试下db class\n",
    "# pdb.set_trace()\n",
    "\n",
    "def sample_db():\n",
    "    db = DB()\n",
    "    inventory_def = {'year': int, 'kind': str, 'company': str, 'model': str}\n",
    "    db.create_table('inventory', inventory_def)\n",
    "    return db\n",
    "\n",
    "db = sample_db()\n",
    "db.table('inventory')\n",
    "db.sql('insert into inventory (year, kind, company, model) values (1997, \"van\", \"Ford\", \"E350\")')\n",
    "db.sql('select year from inventory where year == 1997')\n",
    "db.sql('update inventory set year = 1998 where year == 1997')\n",
    "db.sql('delete from inventory where company == \"Ford\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用我们的数据，生成一张表\n",
    "db = DB()\n",
    "inventory_def = {'year': int, 'kind': str, 'company': str, 'model': str}\n",
    "db.create_table('inventory', inventory_def)\n",
    "\n",
    "def update_inventory(sqldb, vehicle):\n",
    "    inventory_def = sqldb.db['inventory'][0]\n",
    "    k, v = zip(*inventory_def.items())\n",
    "    val = [repr(cast(val)) for cast, val in zip(v, vehicle.split(','))]\n",
    "    sqldb.sql('insert into inventory (%s) values (%s)' % (','.join(k),\n",
    "                                                          ','.join(val)))\n",
    "\n",
    "for V in VEHICLES:\n",
    "    update_inventory(db, V)\n",
    "\n",
    "db.db"
   ]
  },
  {
   "source": [
    "## Fuzzing SQL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPR_GRAMMAR = {\n",
    "    \"<start>\": [\"<expr>\"],\n",
    "    \"<expr>\": [\"<bexpr>\", \"<aexpr>\", \"(<expr>)\", \"<term>\"],\n",
    "    \"<bexpr>\": [\n",
    "        \"<aexpr><lt><aexpr>\",\n",
    "        \"<aexpr><gt><aexpr>\",\n",
    "        \"<expr>==<expr>\",\n",
    "        \"<expr>!=<expr>\",\n",
    "    ],\n",
    "    \"<aexpr>\": [\n",
    "        \"<aexpr>+<aexpr>\", \"<aexpr>-<aexpr>\", \"<aexpr>*<aexpr>\",\n",
    "        \"<aexpr>/<aexpr>\", \"<word>(<exprs>)\", \"<expr>\"\n",
    "    ],\n",
    "    \"<exprs>\": [\"<expr>,<exprs>\", \"<expr>\"],\n",
    "    \"<lt>\": [\"<\"],\n",
    "    \"<gt>\": [\">\"],\n",
    "    \"<term>\": [\"<number>\", \"<word>\"],\n",
    "    \"<number>\": [\"<integer>.<integer>\", \"<integer>\", \"-<number>\"],\n",
    "    \"<integer>\": [\"<digit><integer>\", \"<digit>\"],\n",
    "    \"<word>\": [\"<word><letter>\", \"<word><digit>\", \"<letter>\"],\n",
    "    \"<digit>\":\n",
    "    list(string.digits),\n",
    "    \"<letter>\":\n",
    "    list(string.ascii_letters + '_:.')\n",
    "}\n",
    "\n",
    "\n",
    "INVENTORY_GRAMMAR = dict(\n",
    "    EXPR_GRAMMAR, **{\n",
    "        '<start>': ['<query>'],\n",
    "        '<query>': [\n",
    "            'select <exprs> from <table>',\n",
    "            'select <exprs> from <table> where <bexpr>',\n",
    "            'insert into <table> (<names>) values (<literals>)',\n",
    "            'update <table> set <assignments> where <bexpr>',\n",
    "            'delete from <table> where <bexpr>',\n",
    "        ],\n",
    "        '<table>': ['<word>'],\n",
    "        '<names>': ['<column>,<names>', '<column>'],\n",
    "        '<column>': ['<word>'],\n",
    "        '<literals>': ['<literal>', '<literal>,<literals>'],\n",
    "        '<literal>': ['<number>', \"'<chars>'\"],\n",
    "        '<assignments>': ['<kvp>,<assignments>', '<kvp>'],\n",
    "        '<kvp>': ['<column>=<value>'],\n",
    "        '<value>': ['<word>'],\n",
    "        '<chars>': ['<char>', '<char><chars>'],\n",
    "        '<char>':\n",
    "        [i for i in string.printable if i not in \"<>'\\\"\\t\\n\\r\\x0b\\x0c\\x00\"\n",
    "         ] + ['<lt>', '<gt>'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVENTORY_GRAMMAR_F = dict(INVENTORY_GRAMMAR, **{'<table>': ['inventory']})\n",
    "from fuzzingbook.fuzzingbook_utils.GrammarFuzzer import GrammarFuzzer\n",
    "\n",
    "gf = GrammarFuzzer(INVENTORY_GRAMMAR_F)\n",
    "for _ in range(10):\n",
    "    query = gf.fuzz()\n",
    "    print(repr(query))\n",
    "    try:\n",
    "        res = db.sql(query)\n",
    "        print(repr(res))\n",
    "    except SQLException as e:\n",
    "        print(\"> \", e)\n",
    "        pass\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash 并不是唯一的错误指标。\n",
    "# 起始这也不是问题。选出来的内容，本来就是可以进行处理。\n",
    "db.sql('select year - 1900 if year < 2000 else year - 2000 from inventory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重现上面的错误\n",
    "# 类似于systeem这种错误\n",
    "years = [1997,2000,1999]\n",
    "ans = []\n",
    "for year in years:\n",
    "    ans.append( eval('year - 1900 if year < 2000 else year - 2000',{},{\"year\":year}) )\n",
    "print(ans)"
   ]
  },
  {
   "source": [
    "One method that allows such differentiation is that of dynamic taint analysis. The idea is to identify the functions that accept user input as sources that taint any string that comes in through them, and those functions that perform dangerous operations as sinks. Finally we bless certain functions as taint sanitizers. The idea is that an input from the source should never reach the sink without undergoing sanitization first. This allows us to use a stronger oracle than simply checking for crashes.（大概意思是：用户输入的数据被进行污点标记。通过它们计算得到的数据，也同样会被标记。当这些污点数据到达sanks的时候，可能会造成安全问题。可以通过无害处理，避免污点数据到达sanks。。而如果不进行无害处理，也无法到达sanks，则说明是安全的）\n",
    "\n",
    "\n",
    "污点分析可以抽象成一个三元组<sources,sinks,sanitizers>的形式,其中,source 即污点源,代表直接引入不受信任的数据或者机密数据到系统中;sink即污点汇聚点,代表直接产生安全敏感操作(违反数据完整性)或者泄露隐私数据到外界(违反数据保密性);sanitizer即无害处理,代表通过数据加密或者移除危害操作等手段使数据传播不再对软件系统的信息安全产生危害.污点分析就是分析程序中由污点源引入的数据是否能够不经无害处理,而直接传播到污点汇聚点.如果不能,说明系统是信息流安全的;否则,说明系统产生了隐私数据泄露或危险数据操作等安全问题。\n",
    "\n",
    "\n",
    "[简单理解污点分析技术](https://www.k0rz3n.com/2019/03/01/%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90%E6%8A%80%E6%9C%AF/#0X03-%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90%E5%9C%A8%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 字符串污点标记"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############    包装str类。我查了很长时间，没有弄明白。\n",
    "# new方法创建实例。init方法初始化实例。\n",
    "# 这里的new方法中的value参数，大概是str类需要的字符串变量，用以创建对象。\n",
    "# 但是，我没找见str类的__new__方法介绍。\n",
    "class tstr(str):\n",
    "    def __new__(cls, value, *args, **kw):\n",
    "        return str.__new__(cls, value)\n",
    "\n",
    "    def __init__(self, value, taint=None, **kwargs):\n",
    "        self.taint = taint\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return tstr(str.__repr__(self), taint=self.taint)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str.__str__(self)\n",
    "    \n",
    "    def __radd__(self, s):\n",
    "        return self.create(s + str(self))\n",
    "    \n",
    "    # 附带消除污点和检查是否污点设置的方法\n",
    "    def clear_taint(self):\n",
    "        self.taint = None\n",
    "        return self\n",
    "\n",
    "    def has_taint(self):\n",
    "        return self.taint is not None\n",
    "    \n",
    "    # 给已经存在的字符串添加污点标记，返回带污点标记的新字符串\n",
    "    def create(self, s):\n",
    "        return tstr(s, taint=self.taint)\n",
    "\n",
    "## 将字符串处理函数的结果，添加污点标记\n",
    "def make_str_wrapper(fun):\n",
    "    def proxy(self, *args, **kwargs):\n",
    "        res = fun(self, *args, **kwargs)\n",
    "        return self.create(res)\n",
    "    return proxy\n",
    "\n",
    "\n",
    "def informationflow_init_1():\n",
    "    for name in ['__format__', '__mod__', '__rmod__', '__getitem__', '__add__', '__mul__', '__rmul__',\n",
    "                 'capitalize', 'casefold', 'center', 'encode',\n",
    "                 'expandtabs', 'format', 'format_map', 'join', 'ljust', 'lower', 'lstrip', 'replace',\n",
    "                 'rjust', 'rstrip', 'strip', 'swapcase', 'title', 'translate', 'upper']:\n",
    "        fun = getattr(str, name)\n",
    "        setattr(tstr, name, make_str_wrapper(fun))\n",
    "\n",
    "# 设置setattr的其他方法\n",
    "# 这个咋不放在__init__方法中呢？\n",
    "informationflow_init_1()\n",
    "\n",
    "\n",
    "# INITIALIZER_LIST = [informationflow_init_1]\n",
    "# def initialize():\n",
    "#     for fn in INITIALIZER_LIST:\n",
    "#         fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由此，经过hello运算的字符串，都会被污点标记\n",
    "thello = tstr('hello', taint='LOW')\n",
    "\n",
    "print(thello[0].taint)\n",
    "print(thello[1:3].taint)\n",
    "print((tstr('foo', taint='HIGH') + 'bar').taint)\n",
    "print(('foo' + tstr('bar', taint='HIGH')).taint)\n",
    "# print((thello += ', world').taint)\n",
    "print((thello * 5).taint)\n",
    "print(('hw %s' % thello).taint)\n",
    "print((tstr('hello %s', taint='HIGH') % 'world').taint)"
   ]
  },
  {
   "source": [
    "## 跟踪不信任的输入"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrustedDB(DB):\n",
    "    def sql(self, s):\n",
    "        # 标记为TRUSTED的输入，才能被sql执行\n",
    "        assert isinstance(s, tstr), \"Need a tainted string\"\n",
    "        assert s.taint == 'TRUSTED', \"Need a string with trusted taint\"\n",
    "        return super().sql(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用之前创建的数据库db进行初始化\n",
    "bdb = TrustedDB(db.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行失败\n",
    "# bdb.sql(tstr(\"select year from INVENTORY\"))\n",
    "bdb.sql(tstr(\"select year from inventory\",taint=\"TRUSTED\"))"
   ]
  },
  {
   "source": [
    "所以我们需要进行消毒处理。将不信任的输入，转换成信任的输入。\n",
    "\n",
    "这个转换过程，要求可以判断合法性。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(user_input):\n",
    "    assert isinstance(user_input, tstr)\n",
    "    if re.match(\n",
    "            r'^select +[-a-zA-Z0-9_, ()]+ from +[-a-zA-Z0-9_, ()]+$', user_input):\n",
    "        return tstr(user_input, taint='TRUSTED')\n",
    "    else:\n",
    "        return tstr('', taint='UNTRUSTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_user_input = tstr(\"select year,model from inventory\", taint='UNTRUSTED')\n",
    "sanitized_input = sanitize(good_user_input)\n",
    "print(sanitized_input)\n",
    "print(sanitized_input.taint)\n",
    "bdb.sql(sanitized_input)"
   ]
  },
  {
   "source": [
    "## Taint Aware Fuzzing\n",
    "\n",
    "污点导向的模糊测试。这些模糊测试采用语法生成输入，生成的输入可能是危险的输入。核心思想是生成的输入导致不可信的执行，我们可以留意这些输入。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tainted(Exception):\n",
    "    def __init__(self, v):\n",
    "        self.v = v\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Tainted[%s]' % self.v\n",
    "\n",
    "\n",
    "class TaintedDB(DB):\n",
    "    def my_eval(self, statement, g, l):\n",
    "        if statement.taint != 'TRUSTED':\n",
    "            raise Tainted(statement)\n",
    "        try:\n",
    "            return eval(statement, g, l)\n",
    "        except:\n",
    "            raise SQLException('Invalid SQL (%s)' % repr(statement))\n",
    "\n",
    "# tdb = TaintedDB()\n",
    "# tdb.db = db.db\n",
    "tdb = TaintedDB(db.db)\n",
    "\n",
    "import traceback\n",
    "for _ in range(10):\n",
    "    query = gf.fuzz()\n",
    "    print(repr(query))\n",
    "    try:\n",
    "        res = tdb.sql(tstr(query, taint='UNTRUSTED'))\n",
    "        print(repr(res))\n",
    "    except SQLException as e:\n",
    "        # pass\n",
    "        print(\">> \", e)\n",
    "    except Tainted as e:\n",
    "        print(\"> \", e)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        break\n",
    "    print()"
   ]
  },
  {
   "source": [
    "污点标记可以有下面功能：避免隐私数据泄露(对于一些隐私关键数据进行标记。如果检查出存在该标记，则说明可能隐私泄露，阻止该操作)。\n",
    "\n",
    "但是，当两个不同标记的字符串相遇的时候，该如何处理？（用优先级处理？）\n",
    "\n",
    "更详细的是，对应给定的字符串，每一个字符都知道其来源。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 追踪字符起源\n",
    "\n",
    "让我们引入一个类ostr，它和tstr一样，为每个字符串携带一个污点，另外为每个字符携带一个表示其来源的origin。它是一个在特定范围内的连续数字(默认情况下，从零开始)，表示它在特定原点内的位置。\n",
    "\n",
    "我复制了一些代码过来。要实现给一个类，添加附加信息，似乎并不是一件容易的事情。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ostr(str):\n",
    "    DEFAULT_ORIGIN = 0\n",
    "\n",
    "    def __new__(cls, value, *args, **kw):\n",
    "        return str.__new__(cls, value)\n",
    "\n",
    "    def __init__(self, value, taint=None, origin=None, **kwargs):\n",
    "        self.taint = taint\n",
    "\n",
    "        if origin is None:\n",
    "            origin = ostr.DEFAULT_ORIGIN\n",
    "        if isinstance(origin, int):\n",
    "            self.origin = list(range(origin, origin + len(self)))\n",
    "        else:\n",
    "            self.origin = origin\n",
    "        assert len(self.origin) == len(self)\n",
    "\n",
    "\n",
    "    # def create(self, s):\n",
    "    #     return ostr(s, taint=self.taint, origin=self.origin)\n",
    "    \n",
    "\n",
    "    UNKNOWN_ORIGIN = -1\n",
    "    def __repr__(self):\n",
    "        # handle escaped chars\n",
    "        origin = [ostr.UNKNOWN_ORIGIN]\n",
    "        for s, o in zip(str(self), self.origin):\n",
    "            # len(repr('\\n'))==4==2(两个引号)+2(\\\\n)\n",
    "            # len(repr('a'))==3==2(两个引号)+1(a)\n",
    "            origin.extend([o] * (len(repr(s)) - 2))\n",
    "        origin.append(ostr.UNKNOWN_ORIGIN)\n",
    "        return ostr(str.__repr__(self), taint=self.taint, origin=origin)\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return str.__str__(self)\n",
    "    \n",
    "\n",
    "    def clear_taint(self):\n",
    "        self.taint = None\n",
    "        return self\n",
    "\n",
    "    def has_taint(self):\n",
    "        return self.taint is not None\n",
    "\n",
    "\n",
    "    def clear_origin(self):\n",
    "        self.origin = [self.UNKNOWN_ORIGIN] * len(self)\n",
    "        return self\n",
    "\n",
    "    def has_origin(self):\n",
    "        return any(origin != self.UNKNOWN_ORIGIN for origin in self.origin)\n",
    "\n",
    "\n",
    "    def create(self, res, origin=None):\n",
    "        return ostr(res, taint=self.taint, origin=origin)\n",
    "\n",
    "\n",
    "    ######### 重现字符串的一些功能 ###############\n",
    "    def __getitem__(self, key):\n",
    "        # 通过下标或者slice获取ostr的指定内容\n",
    "        res = super().__getitem__(key)\n",
    "        if isinstance(key, int):\n",
    "            key = len(self) + key if key < 0 else key\n",
    "            return self.create(res, [self.origin[key]])\n",
    "        elif isinstance(key, slice):\n",
    "            return self.create(res, self.origin[key])\n",
    "        else:\n",
    "            assert False\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # [n:m]这样的方式获取切片\n",
    "        return ostr_iterator(self)\n",
    "\n",
    "    class ostr_iterator():\n",
    "        def __init__(self, ostr):\n",
    "            self._ostr = ostr\n",
    "            self._str_idx = 0\n",
    "\n",
    "        def __next__(self):\n",
    "            if self._str_idx == len(self._ostr):\n",
    "                raise StopIteration\n",
    "            # calls ostr getitem should be ostr\n",
    "            c = self._ostr[self._str_idx]\n",
    "            assert isinstance(c, ostr)\n",
    "            self._str_idx += 1\n",
    "            return c\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, ostr):\n",
    "            return self.create(str.__add__(self, other),\n",
    "                               (self.origin + other.origin))\n",
    "        else:\n",
    "            return self.create(str.__add__(self, other),\n",
    "                               (self.origin + [self.UNKNOWN_ORIGIN for i in other]))\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        origin = other.origin if isinstance(other, ostr) else [\n",
    "            self.UNKNOWN_ORIGIN for i in other]\n",
    "        return self.create(str.__add__(other, self), (origin + self.origin))\n",
    "\n",
    "\n",
    "    class TaintException(Exception):\n",
    "        pass\n",
    "\n",
    "    def x(self, i=0):\n",
    "        # 根据origin从该字符串中提取内容\n",
    "        if not self.origin:\n",
    "            raise origin.TaintException('Invalid request idx')\n",
    "        if isinstance(i, int):\n",
    "            return [self[p]\n",
    "                    for p in [k for k, j in enumerate(self.origin) if j == i]]\n",
    "        elif isinstance(i, slice):\n",
    "            r = range(i.start or 0, i.stop or len(self), i.step or 1)\n",
    "            return [self[p]\n",
    "                    for p in [k for k, j in enumerate(self.origin) if j in r]]\n",
    "\n",
    "    def replace(self, a, b, n=None):\n",
    "        old_origin = self.origin\n",
    "        b_origin = b.origin if isinstance(\n",
    "            b, ostr) else [self.UNKNOWN_ORIGIN] * len(b)\n",
    "        mystr = str(self)\n",
    "        i = 0\n",
    "        while True:\n",
    "            if n and i >= n:\n",
    "                break\n",
    "            idx = mystr.find(a)\n",
    "            if idx == -1:\n",
    "                break\n",
    "            last = idx + len(a)\n",
    "            mystr = mystr.replace(a, b, 1)\n",
    "            partA, partB = old_origin[0:idx], old_origin[last:]\n",
    "            old_origin = partA + b_origin + partB\n",
    "            i += 1\n",
    "        return self.create(mystr, old_origin)\n",
    "\n",
    "\n",
    "    def replace(self, a, b, n=None):\n",
    "        #  replaces a portion of the string with another.\n",
    "        old_origin = self.origin\n",
    "        b_origin = b.origin if isinstance(\n",
    "            b, ostr) else [self.UNKNOWN_ORIGIN] * len(b)\n",
    "        mystr = str(self)\n",
    "        i = 0\n",
    "        while True:\n",
    "            if n and i >= n:\n",
    "                break\n",
    "            idx = mystr.find(a)\n",
    "            if idx == -1:\n",
    "                break\n",
    "            last = idx + len(a)\n",
    "            mystr = mystr.replace(a, b, 1)\n",
    "            partA, partB = old_origin[0:idx], old_origin[last:]\n",
    "            old_origin = partA + b_origin + partB\n",
    "            i += 1\n",
    "        return self.create(mystr, old_origin)\n",
    "\n",
    "\n",
    "    def _split_helper(self, sep, splitted):\n",
    "        result_list = []\n",
    "        last_idx = 0\n",
    "        first_idx = 0\n",
    "        sep_len = len(sep)\n",
    "\n",
    "        for s in splitted:\n",
    "            last_idx = first_idx + len(s)\n",
    "            item = self[first_idx:last_idx]\n",
    "            result_list.append(item)\n",
    "            first_idx = last_idx + sep_len\n",
    "        return result_list\n",
    "\n",
    "    def _split_space(self, splitted):\n",
    "        result_list = []\n",
    "        last_idx = 0\n",
    "        first_idx = 0\n",
    "        sep_len = 0\n",
    "        for s in splitted:\n",
    "            last_idx = first_idx + len(s)\n",
    "            item = self[first_idx:last_idx]\n",
    "            result_list.append(item)\n",
    "            v = str(self[last_idx:])\n",
    "            sep_len = len(v) - len(v.lstrip(' '))\n",
    "            first_idx = last_idx + sep_len\n",
    "        return result_list\n",
    "\n",
    "    def rsplit(self, sep=None, maxsplit=-1):\n",
    "        splitted = super().rsplit(sep, maxsplit)\n",
    "        if not sep:\n",
    "            return self._split_space(splitted)\n",
    "        return self._split_helper(sep, splitted)\n",
    "\n",
    "    def split(self, sep=None, maxsplit=-1):\n",
    "        splitted = super().split(sep, maxsplit)\n",
    "        if not sep:\n",
    "            return self._split_space(splitted)\n",
    "        return self._split_helper(sep, splitted)\n",
    "\n",
    "\n",
    "    def strip(self, cl=None):\n",
    "        return self.lstrip(cl).rstrip(cl)\n",
    "\n",
    "    def lstrip(self, cl=None):\n",
    "        res = super().lstrip(cl)\n",
    "        i = self.find(res)\n",
    "        return self[i:]\n",
    "\n",
    "    def rstrip(self, cl=None):\n",
    "        res = super().rstrip(cl)\n",
    "        return self[0:len(res)]\n",
    "\n",
    "    def expandtabs(self, n=8):\n",
    "        parts = self.split('\\t')\n",
    "        res = super().expandtabs(n)\n",
    "        all_parts = []\n",
    "        for i, p in enumerate(parts):\n",
    "            all_parts.extend(p.origin)\n",
    "            if i < len(parts) - 1:\n",
    "                l = len(all_parts) % n\n",
    "                all_parts.extend([p.origin[-1]] * l)\n",
    "        return self.create(res, all_parts)\n",
    "    \n",
    "\n",
    "    def join(self, iterable):\n",
    "        mystr = ''\n",
    "        myorigin = []\n",
    "        sep_origin = self.origin\n",
    "        lst = list(iterable)\n",
    "        for i, s in enumerate(lst):\n",
    "            sorigin = s.origin if isinstance(s, ostr) else [\n",
    "                self.UNKNOWN_ORIGIN] * len(s)\n",
    "            myorigin.extend(sorigin)\n",
    "            mystr += str(s)\n",
    "            if i < len(lst) - 1:\n",
    "                myorigin.extend(sep_origin)\n",
    "                mystr += str(self)\n",
    "        res = super().join(iterable)\n",
    "        assert len(res) == len(mystr)\n",
    "        return self.create(res, myorigin)\n",
    "    \n",
    "\n",
    "    def partition(self, sep):\n",
    "        partA, sep, partB = super().partition(sep)\n",
    "        return (self.create(partA, self.origin[0:len(partA)]),\n",
    "                self.create(sep,\n",
    "                            self.origin[len(partA):len(partA) + len(sep)]),\n",
    "                self.create(partB, self.origin[len(partA) + len(sep):]))\n",
    "\n",
    "    def rpartition(self, sep):\n",
    "        partA, sep, partB = super().rpartition(sep)\n",
    "        return (self.create(partA, self.origin[0:len(partA)]),\n",
    "                self.create(sep,\n",
    "                            self.origin[len(partA):len(partA) + len(sep)]),\n",
    "                self.create(partB, self.origin[len(partA) + len(sep):]))\n",
    "    \n",
    "\n",
    "    def ljust(self, width, fillchar=' '):\n",
    "        res = super().ljust(width, fillchar)\n",
    "        initial = len(res) - len(self)\n",
    "        if isinstance(fillchar, tstr):\n",
    "            t = fillchar.x()\n",
    "        else:\n",
    "            t = self.UNKNOWN_ORIGIN\n",
    "        return self.create(res, [t] * initial + self.origin)\n",
    "    \n",
    "\n",
    "    def rjust(self, width, fillchar=' '):\n",
    "        res = super().rjust(width, fillchar)\n",
    "        final = len(res) - len(self)\n",
    "        if isinstance(fillchar, tstr):\n",
    "            t = fillchar.x()\n",
    "        else:\n",
    "            t = self.UNKNOWN_ORIGIN\n",
    "        return self.create(res, self.origin + [t] * final)\n",
    "    \n",
    "\n",
    "    def __mod__(self, s):\n",
    "        # nothing else implemented for the time being\n",
    "        assert isinstance(s, str)\n",
    "        s_origin = s.origin if isinstance(\n",
    "            s, ostr) else [self.UNKNOWN_ORIGIN] * len(s)\n",
    "        i = self.find('%s')\n",
    "        assert i >= 0\n",
    "        res = super().__mod__(s)\n",
    "        r_origin = self.origin[:]\n",
    "        r_origin[i:i + 2] = s_origin\n",
    "        return self.create(res, origin=r_origin)\n",
    "    \n",
    "    def __rmod__(self, s):\n",
    "        # nothing else implemented for the time being\n",
    "        assert isinstance(s, str)\n",
    "        r_origin = s.origin if isinstance(\n",
    "            s, ostr) else [self.UNKNOWN_ORIGIN] * len(s)\n",
    "        i = s.find('%s')\n",
    "        assert i >= 0\n",
    "        res = super().__rmod__(s)\n",
    "        s_origin = self.origin[:]\n",
    "        r_origin[i:i + 2] = s_origin\n",
    "        return self.create(res, origin=r_origin)\n",
    "    \n",
    "    def swapcase(self):\n",
    "        return self.create(str(self).swapcase(), self.origin)\n",
    "\n",
    "    def upper(self):\n",
    "        return self.create(str(self).upper(), self.origin)\n",
    "\n",
    "    def lower(self):\n",
    "        return self.create(str(self).lower(), self.origin)\n",
    "\n",
    "    def capitalize(self):\n",
    "        return self.create(str(self).capitalize(), self.origin)\n",
    "\n",
    "    def title(self):\n",
    "        return self.create(str(self).title(), self.origin)\n",
    "    \n",
    "    ######等等......\n",
    "    \n",
    "# def make_split_wrapper(fun):\n",
    "#     def proxy(self, *args, **kwargs):\n",
    "#         lst = fun(self, *args, **kwargs)\n",
    "#         return [self.create(elem) for elem in lst]\n",
    "#     return proxy\n",
    "\n",
    "# for name in ['split', 'rsplit', 'splitlines']:\n",
    "#     fun = getattr(str, name)\n",
    "#     setattr(ostr, name, make_split_wrapper(fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thello = ostr('hello', taint='HIGH')\n",
    "assert thello.origin == [0, 1, 2, 3, 4]\n",
    "\n",
    "tworld = thello.create('world', origin=6)\n",
    "assert (thello.origin, tworld.origin) == ([0, 1, 2, 3, 4], [6, 7, 8, 9, 10])"
   ]
  },
  {
   "source": [
    "## Taint-Directed Fuzzing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from fuzzingbook.fuzzingbook_utils.Grammars import START_SYMBOL\n",
    "from fuzzingbook.fuzzingbook_utils.GrammarFuzzer import GrammarFuzzer\n",
    "from fuzzingbook.fuzzingbook_utils.Parser import canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedGrammarFuzzer(GrammarFuzzer):\n",
    "    def __init__(self,\n",
    "                 grammar,\n",
    "                 start_symbol=START_SYMBOL,\n",
    "                 expansion_switch=1,\n",
    "                 log=False):\n",
    "        # expansion_switch为阈值。小于它的时候，随机扩展；大于它的时候，使用最小代价扩展。\n",
    "        self.tainted_start_symbol = ostr(\n",
    "            start_symbol, origin=[1] * len(start_symbol))\n",
    "        self.expansion_switch = expansion_switch\n",
    "        self.log = log\n",
    "        self.grammar = grammar\n",
    "        self.c_grammar = canonical(grammar)\n",
    "        self.init_tainted_grammar()\n",
    "\n",
    "\n",
    "    def init_tainted_grammar(self):\n",
    "        # 给语法中的终结符和非终结符，都使用了int进行tainted标记\n",
    "        # 因为都是1000,100,10之间的间隔比较啊，如果语法中的表达式没有那么长的话，应该不会冲突。\n",
    "        # 这里的冲突，指的是，不同的字符，使用了相同的tainted。\n",
    "        key_increment, alt_increment, token_increment = 1000, 100, 10\n",
    "        key_origin = key_increment\n",
    "        self.ct_grammar = {}\n",
    "        for key, val in self.c_grammar.items():\n",
    "            key_origin += key_increment\n",
    "            os = []\n",
    "            for v in val:\n",
    "                ts = []\n",
    "                key_origin += alt_increment\n",
    "                for t in v:\n",
    "                    nt = ostr(t, origin=key_origin)\n",
    "                    key_origin += token_increment\n",
    "                    ts.append(nt)\n",
    "                os.append(ts)\n",
    "            self.ct_grammar[key] = os\n",
    "\n",
    "        # a use tracking grammar\n",
    "        self.ctp_grammar = {}\n",
    "        for key, val in self.ct_grammar.items():\n",
    "            self.ctp_grammar[key] = [(v, dict(use=0)) for v in val]\n",
    "\n",
    "    def expansion_cost(self, expansion, seen=set()):\n",
    "        symbols = [e for e in expansion if e in self.c_grammar]\n",
    "        if len(symbols) == 0:\n",
    "            return 1\n",
    "\n",
    "        if any(s in seen for s in symbols):\n",
    "            return float('inf')\n",
    "\n",
    "        return sum(self.symbol_cost(s, seen) for s in symbols) + 1\n",
    "\n",
    "    def fuzz_tree(self):\n",
    "        tree = (self.tainted_start_symbol, [])\n",
    "        nt_leaves = [tree]\n",
    "        expansion_trials = 0\n",
    "        while nt_leaves:\n",
    "            idx = random.randint(0, len(nt_leaves) - 1)\n",
    "            key, children = nt_leaves[idx]\n",
    "            expansions = self.ct_grammar[key]\n",
    "            if expansion_trials < self.expansion_switch:\n",
    "                expansion = random.choice(expansions)\n",
    "            else:\n",
    "                costs = [self.expansion_cost(e) for e in expansions]\n",
    "                m = min(costs)\n",
    "                all_min = [i for i, c in enumerate(costs) if c == m]\n",
    "                expansion = expansions[random.choice(all_min)]\n",
    "\n",
    "            new_leaves = [(token, []) for token in expansion]\n",
    "            new_nt_leaves = [e for e in new_leaves if e[0] in self.ct_grammar]\n",
    "            children[:] = new_leaves # 问题是，如何将children回写到树中位置？？\n",
    "            nt_leaves[idx:idx + 1] = new_nt_leaves # 当前父节点，被，选中expansion中的非终结符(s)替代\n",
    "            if self.log:\n",
    "                print(\"%-40s\" % (key + \" -> \" + str(expansion)))\n",
    "            expansion_trials += 1\n",
    "        return tree\n",
    "\n",
    "    def fuzz(self):\n",
    "        self.derivation_tree = self.fuzz_tree()\n",
    "        return self.tree_to_string(self.derivation_tree)\n",
    "    \n",
    "\n",
    "    def tree_to_string(self, tree):\n",
    "        symbol, children, *_ = tree\n",
    "        e = ostr('')\n",
    "        if children:\n",
    "            return e.join([self.tree_to_string(c) for c in children])\n",
    "        else:\n",
    "            return e if symbol in self.c_grammar else symbol\n",
    "        \n",
    "    def update_grammar(self, origin, dtree):\n",
    "        # 根据输出，可以看出，给使用过的语法+1\n",
    "        # 递归的(if和else)结果，存放在updated_children的list中\n",
    "        def update_tree(dtree, origin):\n",
    "            key, children = dtree\n",
    "            if children:\n",
    "                updated_children = [update_tree(c, origin) for c in children]\n",
    "                corigin = set.union(\n",
    "                    *[o for (key, children, o) in updated_children])\n",
    "                corigin = corigin.union(set(key.origin))\n",
    "                return (key, children, corigin)\n",
    "            else:\n",
    "                my_origin = set(key.origin).intersection(origin)\n",
    "                return (key, [], my_origin)\n",
    "\n",
    "        key, children, oset = update_tree(dtree, set(origin))\n",
    "        for key, alts in self.ctp_grammar.items():\n",
    "            for alt, o in alts:\n",
    "                alt_origins = set([i for token in alt for i in token.origin])\n",
    "                if alt_origins.intersection(oset):\n",
    "                    o['use'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingDB(TaintedDB):\n",
    "    def my_eval(self, statement, g, l):\n",
    "        if statement.origin:\n",
    "            raise Tainted(statement)\n",
    "        try:\n",
    "            return eval(statement, g, l)\n",
    "        except:\n",
    "            raise SQLException('Invalid SQL (%s)' % repr(statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tree_type(tree):\n",
    "    key, children = tree\n",
    "    return (type(key), key, [tree_type(c) for c in children])\n",
    "\n",
    "trdb = TrackingDB(db.db)\n",
    "tgf = TaintedGrammarFuzzer(INVENTORY_GRAMMAR_F)\n",
    "x = None\n",
    "for _ in range(10):\n",
    "    qtree = tgf.fuzz_tree()\n",
    "    query = tgf.tree_to_string(qtree)\n",
    "    assert isinstance(query, ostr)\n",
    "    try:\n",
    "        print(repr(query))\n",
    "        res = trdb.sql(query)\n",
    "        print(repr(res))\n",
    "    except SQLException as e:\n",
    "        print(e)\n",
    "    except Tainted as e:\n",
    "        print(e)\n",
    "        origin = e.args[0].origin\n",
    "        tgf.update_grammar(origin, qtree)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgf.ctp_grammar"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "* String-based and character-based taints allow to dynamically track the information flow from input to the internals of a system and back to the output.\n",
    "\n",
    "    基于字符串和基于字符的污染允许动态跟踪从输入到系统内部并返回到输出的信息流。\n",
    "\n",
    "* Checking taints allows to discover untrusted inputs and information leakage at runtime.\n",
    "\n",
    "    检查污染可以在运行时发现不可信的输入和信息泄漏。\n",
    "\n",
    "* Data conversions and implicit data flow may strip taint information; the resulting untainted strings should be treated as having the worst possible taint.\n",
    "\n",
    "    数据转换和隐式数据流可能会剥离污染信息;产生的未受污染的字符串应被视为具有可能的最严重污染。\n",
    "\n",
    "* Taints can be used in conjunction with fuzzing to provide a more robust indication of incorrect behavior than to simply rely on program crashes.\n",
    "\n",
    "    污点可以与fuzzing一起使用，以提供不正确行为的更可靠指示，而不是简单地依赖于程序崩溃。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}